# conversation_interface.py
"""
InterfÃ­cie conversacional per a SVGelona_AI 5.2
Ara amb suport per a mÃºltiples configuracions i comandes avanÃ§ades.
"""
import sys
import os
import json
from typing import Dict, List, Any, Optional
import argparse

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from main_v5_2 import SVGelonaAI5_2
from config_v5_2 import (
    get_config, 
    get_config_object, 
    list_available_configs,
    create_custom_config,
    validate_config,
    optimize_config_for_hardware,
    print_config_summary,
    ALL_CONFIGS
)

class ConversationalSVGelona:
    """Classe millorada per a gestiÃ³ de conversacions."""
    
    def __init__(self, config_name: str = "conversational", custom_config: Optional[Dict] = None):
        """
        Inicialitza el sistema conversacional.
        
        Args:
            config_name: Nom de la configuraciÃ³ a utilitzar
            custom_config: ConfiguraciÃ³ personalitzada opcional
        """
        print("=" * 80)
        print("SVGelona_AI 5.2 - InterfÃ­cie Conversacional AvanÃ§ada")
        print("=" * 80)
        
        # Carregar configuraciÃ³
        if custom_config:
            config = custom_config
            print("âœ“ ConfiguraciÃ³ personalitzada carregada")
        else:
            if config_name in ALL_CONFIGS:
                config_obj = get_config_object(config_name)
                config = config_obj.config.copy()
                print(f"âœ“ ConfiguraciÃ³ '{config_name}' carregada: {config_obj.description}")
            else:
                print(f"âš  ConfiguraciÃ³ '{config_name}' no trobada, usant 'conversational'")
                config_obj = get_config_object("conversational")
                config = config_obj.config.copy()
        
        # Inicialitzar sistema
        self.system = SVGelonaAI5_2(config)
        self.config_name = config_name
        self.config = config
        
        # Historial de conversa
        self.conversation_history = []
        self.command_history = []
        
        # Estats especials
        self.creative_mode = False
        self.visualization_mode = False
        self.learning_mode = True
        
        # Configuracions disponibles
        self.available_configs = list_available_configs()
        
        print(f"\nðŸ’¬ Sistema preparat en mode '{config_name}'")
        print(f"ðŸ“Š ConfiguraciÃ³: {config['performance_mode']}, MemÃ²ria: {config['memory_limit_mb']}MB")
        print(f"ðŸŽ¨ Modes: {'ðŸŸ¢ Creatiu' if self.creative_mode else 'âš« Normal'}")
        print("=" * 80)
    
    def process_command(self, user_input: str) -> Dict[str, Any]:
        """
        Processa una comanda o entrada de l'usuari.
        
        Args:
            user_input: Text introduÃ¯t per l'usuari
            
        Returns:
            Resposta del sistema
        """
        user_input = user_input.strip()
        
        # Guardar en historial
        self.conversation_history.append({
            "role": "user",
            "content": user_input,
            "timestamp": self._get_timestamp()
        })
        
        # Comandes especials
        if user_input.startswith('/'):
            return self._process_special_command(user_input)
        
        # Mode creatiu: interpretar com a inspiraciÃ³ artÃ­stica
        if self.creative_mode:
            return self._process_creative_input(user_input)
        
        # Mode visualitzaciÃ³: interpretar com a descripciÃ³ visual
        if self.visualization_mode:
            return self._process_visual_input(user_input)
        
        # Processament normal: conversa amb el pont semÃ ntic
        return self._process_normal_input(user_input)
    
    def _process_special_command(self, command: str) -> Dict[str, Any]:
        """
        Processa comandes especials (comencen amb /).
        """
        parts = command[1:].split()
        cmd = parts[0].lower() if parts else ""
        args = parts[1:] if len(parts) > 1 else []
        
        response = {
            "type": "command_response",
            "command": cmd,
            "success": True,
            "message": "",
            "data": {}
        }
        
        try:
            if cmd == "help":
                response["message"] = self._get_help_message()
                
            elif cmd == "config":
                if not args:
                    # Mostrar configuraciÃ³ actual
                    response["message"] = self._get_current_config_info()
                elif args[0] == "list":
                    response["message"] = self._list_configs()
                elif args[0] == "switch" and len(args) > 1:
                    new_config = args[1]
                    if new_config in self.available_configs:
                        self._switch_config(new_config)
                        response["message"] = f"Canviat a configuraciÃ³ '{new_config}'"
                    else:
                        response["success"] = False
                        response["message"] = f"ConfiguraciÃ³ '{new_config}' no trobada"
                elif args[0] == "show" and len(args) > 1:
                    config_name = args[1]
                    if config_name in self.available_configs:
                        print_config_summary(config_name)
                        response["message"] = f"Resum de configuraciÃ³ '{config_name}' mostrat"
                    else:
                        response["success"] = False
                        response["message"] = f"ConfiguraciÃ³ '{config_name}' no trobada"
                elif args[0] == "custom":
                    # Crear configuraciÃ³ personalitzada
                    if len(args) > 1:
                        try:
                            params = json.loads(" ".join(args[1:]))
                            custom_config = create_custom_config("default", params)
                            validation = validate_config(custom_config)
                            
                            if validation["is_valid"]:
                                self.system = SVGelonaAI5_2(custom_config)
                                self.config = custom_config
                                response["message"] = "ConfiguraciÃ³ personalitzada aplicada"
                                if validation["warnings"]:
                                    response["message"] += f"\nâš  AdvertÃ¨ncies: {', '.join(validation['warnings'])}"
                            else:
                                response["success"] = False
                                response["message"] = f"âŒ ConfiguraciÃ³ invÃ lida: {', '.join(validation['errors'])}"
                        except json.JSONDecodeError:
                            response["success"] = False
                            response["message"] = "Format JSON invÃ lid"
                
            elif cmd == "mode":
                if not args:
                    response["message"] = self._get_current_modes()
                elif args[0] == "creative":
                    self.creative_mode = not self.creative_mode
                    response["message"] = f"Mode creatiu {'ðŸŸ¢ ACTIU' if self.creative_mode else 'âš« INACTIU'}"
                elif args[0] == "visual":
                    self.visualization_mode = not self.visualization_mode
                    response["message"] = f"Mode visualitzaciÃ³ {'ðŸŸ¢ ACTIU' if self.visualization_mode else 'âš« INACTIU'}"
                elif args[0] == "learning":
                    self.learning_mode = not self.learning_mode
                    response["message"] = f"Mode aprenentatge {'ðŸŸ¢ ACTIU' if self.learning_mode else 'âš« INACTIU'}"
            
            elif cmd == "run":
                steps = int(args[0]) if args and args[0].isdigit() else 3
                generations = int(args[1]) if len(args) > 1 and args[1].isdigit() else 1
                
                for i in range(generations):
                    response["message"] = f"\nExecutant generaciÃ³ {self.system.generation_count + 1}..."
                    result = self.system.run_generation(steps=steps)
                    response["data"][f"generation_{i+1}"] = {
                        "duration": result["duration_seconds"],
                        "coherence": result["evolution"]["final_state"]["coherence"],
                        "fractal_branches": result["fractal_generation"]["branch_count"]
                    }
                
                response["message"] = f"âœ… Executades {generations} generacions amb {steps} passos cada una"
            
            elif cmd == "stats":
                stats = self.system._get_system_state_summary()
                response["message"] = self._format_stats(stats)
            
            elif cmd == "save":
                filename = args[0] if args else "conversation_state.json"
                self.save_conversation_state(filename)
                response["message"] = f"ðŸ’¾ Estat guardat a '{filename}'"
            
            elif cmd == "load":
                filename = args[0] if args else "conversation_state.json"
                if self.load_conversation_state(filename):
                    response["message"] = f"ðŸ“‚ Estat carregat des de '{filename}'"
                else:
                    response["success"] = False
                    response["message"] = f"âš  No s'ha trobat el fitxer '{filename}'"
            
            elif cmd == "optimize":
                optimized_config = optimize_config_for_hardware()
                self.system = SVGelonaAI5_2(optimized_config)
                self.config = optimized_config
                response["message"] = "âš™ï¸  Sistema optimitzat per al teu maquinari"
            
            elif cmd == "benchmark":
                gens = int(args[0]) if args and args[0].isdigit() else 5
                steps = int(args[1]) if len(args) > 1 and args[1].isdigit() else 3
                
                benchmark_result = self.system.run_benchmark(
                    generations=gens, 
                    steps_per_gen=steps
                )
                
                response["message"] = self._format_benchmark(benchmark_result)
            
            elif cmd == "visualize":
                viz_data = self.system.generate_visualization_report()
                filename = "viz_data.json"
                with open(filename, "w") as f:
                    json.dump(viz_data, f, indent=2)
                response["message"] = f"ðŸ“Š Dades de visualitzaciÃ³ generades a '{filename}'"
            
            elif cmd == "export":
                formats = args if args else ["json", "png"]
                self.system.save_system_state("exported_state.json")
                response["message"] = f"ðŸ“¦ Exportat en formats: {', '.join(formats)}"
            
            elif cmd == "reset":
                self.system = SVGelonaAI5_2(self.config)
                response["message"] = "ðŸ”„ Sistema reiniciat amb la configuraciÃ³ actual"
            
            elif cmd == "history":
                response["message"] = self._show_history(args[0] if args else "10")
            
            elif cmd == "clear":
                self.conversation_history = []
                response["message"] = "ðŸ§¹ Historial de conversa esborrat"
            
            else:
                response["success"] = False
                response["message"] = f"Comanda desconeguda: /{cmd}\nUtilitza /help per a veure comandes disponibles"
        
        except Exception as e:
            response["success"] = False
            response["message"] = f"âŒ Error executant comanda: {str(e)}"
        
        # Guardar resposta en historial
        self.conversation_history.append({
            "role": "system",
            "content": response["message"],
            "type": "command",
            "timestamp": self._get_timestamp()
        })
        
        self.command_history.append(cmd)
        return response
    
    def _process_creative_input(self, user_input: str) -> Dict[str, Any]:
        """Processa entrada en mode creatiu."""
        try:
            # Utilitzar pont semÃ ntic per a interpretaciÃ³ creativa
            narrative_response = f"ðŸŽ¨ Mode Creatiu: Interpretant '{user_input}' com a inspiraciÃ³..."
            
            # Generar fractal basat en la descripciÃ³
            result = self.system.run_generation(steps=5)
            
            # Afegir interpretaciÃ³ creativa
            creative_interpretation = self._generate_creative_interpretation(user_input, result)
            
            response = {
                "type": "creative_response",
                "narrative_response": narrative_response + "\n\n" + creative_interpretation,
                "application_result": {
                    "success": True,
                    "parameters_applied": [
                        ("creativity_boost", 0.0, 1.2),
                        ("complexity", result["fractal_generation"]["depth"], 
                         min(15, result["fractal_generation"]["depth"] + 2))
                    ]
                },
                "generation_result": result
            }
            
        except Exception as e:
            response = {
                "type": "error",
                "narrative_response": f"âŒ Error en mode creatiu: {str(e)}",
                "application_result": {"success": False}
            }
        
        # Guardar en historial
        self.conversation_history.append({
            "role": "system",
            "content": response.get("narrative_response", ""),
            "type": "creative",
            "timestamp": self._get_timestamp()
        })
        
        return response
    
    def _process_visual_input(self, user_input: str) -> Dict[str, Any]:
        """Processa entrada en mode visualitzaciÃ³."""
        try:
            # Generar visualitzaciÃ³ basada en la descripciÃ³
            narrative_response = f"ðŸ‘ï¸ Mode Visual: Creant imatge mental de '{user_input}'..."
            
            # Ajustar parÃ metres de renderitzaciÃ³
            self.system.config["render_enabled"] = True
            self.system.config["render_quality"] = "high"
            
            result = self.system.run_generation(steps=3)
            
            response = {
                "type": "visual_response",
                "narrative_response": narrative_response,
                "visual_description": self._generate_visual_description(user_input, result),
                "css_transform": result["fractal_generation"]["css_transform"],
                "application_result": {
                    "success": True,
                    "parameters_applied": [
                        ("render_quality", "medium", "high"),
                        ("visual_detail", 0.5, 0.8)
                    ]
                }
            }
            
        except Exception as e:
            response = {
                "type": "error",
                "narrative_response": f"âŒ Error en mode visual: {str(e)}",
                "application_result": {"success": False}
            }
        
        # Guardar en historial
        self.conversation_history.append({
            "role": "system",
            "content": response.get("narrative_response", ""),
            "type": "visual",
            "timestamp": self._get_timestamp()
        })
        
        return response
    
    def _process_normal_input(self, user_input: str) -> Dict[str, Any]:
        """Processa entrada normal de conversa."""
        try:
            # Utilitzar pont semÃ ntic del sistema
            response_data = self.system.converse_with_ai(user_input)
            
            # Afegir informaciÃ³ adicional si l'aprenentatge estÃ  actiu
            if self.learning_mode and response_data["application_result"]["success"]:
                learned_info = self._extract_learning_points(response_data)
                if learned_info:
                    response_data["narrative_response"] += f"\n\nðŸ“š Aprenentatge: {learned_info}"
            
            return response_data
            
        except Exception as e:
            return {
                "type": "error",
                "narrative_response": f"âŒ Error processant la teva entrada: {str(e)}",
                "application_result": {"success": False}
            }
    
    def _switch_config(self, new_config_name: str):
        """Canvia la configuraciÃ³ del sistema."""
        config_obj = get_config_object(new_config_name)
        self.system = SVGelonaAI5_2(config_obj.config.copy())
        self.config_name = new_config_name
        self.config = config_obj.config.copy()
        print(f"\nðŸ”„ Canviat a configuraciÃ³ '{new_config_name}'")
    
    def _get_help_message(self) -> str:
        """Genera missatge d'ajuda."""
        help_text = """
ðŸ“‹ **COMANDES DISPONIBLES:**

**ConfiguraciÃ³:**
  /config                         Mostrar configuraciÃ³ actual
  /config list                    Llistar totes les configuracions
  /config switch [nom]           Canviar configuraciÃ³
  /config show [nom]             Mostrar resum d'una configuraciÃ³
  /config custom {json}          Aplicar configuraciÃ³ personalitzada

**Modes:**
  /mode                           Mostrar modes actuals
  /mode creative                  Activar/desactivar mode creatiu
  /mode visual                    Activar/desactivar mode visualitzaciÃ³
  /mode learning                  Activar/desactivar aprenentatge

**ExecuciÃ³:**
  /run [passos] [generacions]    Executar generacions
  /benchmark [gens] [passos]     Executar benchmark
  /optimize                      Optimitzar per al maquinari

**InformaciÃ³:**
  /stats                         Mostrar estadÃ­stiques del sistema
  /history [n]                   Mostrar Ãºltimes n entrades d'historial
  /visualize                    Generar dades de visualitzaciÃ³

**GestiÃ³:**
  /save [fitxer]                Guardar estat de conversa
  /load [fitxer]                Carregar estat de conversa
  /export [formats]             Exportar dades
  /reset                        Reiniciar sistema
  /clear                        Esborrar historial de conversa

**Conversa normal:**
  Parla amb l'IA en llenguatge natural!
  Exemples:
    â€¢ "Crea un fractal complex"
    â€¢ "Fes-ho mÃ©s orgÃ nic"
    â€¢ "Explica el que estÃ s pensant"
    â€¢ "Mostra'm la teva memÃ²ria"

**Comandes rÃ pides:**
  exit, quit, q                 Sortir
  help, ?                       Ajuda
"""
        return help_text
    
    def _get_current_config_info(self) -> str:
        """ObtÃ© informaciÃ³ de la configuraciÃ³ actual."""
        config_obj = get_config_object(self.config_name)
        return (f"ðŸ“Š **ConfiguraciÃ³ actual:** {self.config_name}\n"
                f"ðŸ“ DescripciÃ³: {config_obj.description}\n"
                f"âš¡ Mode rendiment: {self.config['performance_mode']}\n"
                f"ðŸ’¾ MemÃ²ria: {self.config['memory_limit_mb']}MB\n"
                f"ðŸŽ¯ Profunditat fractal: {self.config.get('max_fractal_depth', 10)}\n"
                f"ðŸ”§ Pont semÃ ntic: {'ðŸŸ¢ ACTIU' if self.config.get('semantic_bridge_enabled', True) else 'âš« INACTIU'}")
    
    def _list_configs(self) -> str:
        """Llista totes les configuracions disponibles."""
        configs_text = "ðŸ“‹ **Configuracions disponibles:**\n"
        for name in self.available_configs:
            config_obj = get_config_object(name)
            configs_text += f"  â€¢ {name:15} - {config_obj.description}\n"
        return configs_text
    
    def _get_current_modes(self) -> str:
        """ObtÃ© l'estat dels modes actuals."""
        return (f"ðŸŽ­ **Modes actuals:**\n"
                f"  Creatiu: {'ðŸŸ¢ ACTIU' if self.creative_mode else 'âš« INACTIU'}\n"
                f"  VisualitzaciÃ³: {'ðŸŸ¢ ACTIU' if self.visualization_mode else 'âš« INACTIU'}\n"
                f"  Aprenentatge: {'ðŸŸ¢ ACTIU' if self.learning_mode else 'âš« INACTIU'}")
    
    def _format_stats(self, stats: Dict[str, Any]) -> str:
        """Formata estadÃ­stiques del sistema."""
        return (f"ðŸ“ˆ **EstadÃ­stiques del sistema:**\n"
                f"  Generacions: {stats.get('generation_count', 0)}\n"
                f"  Temps actiu: {stats.get('uptime_hours', 0):.1f}h\n"
                f"  Cicatrius: {stats.get('scar_archive', {}).get('total_scars', 0)}\n"
                f"  Axiomes: {stats.get('axiom_system', {}).get('total_axioms', 0)}\n"
                f"  Ãšs memÃ²ria: {self.system.realtime_stats.get('memory_usage_mb', 0):.1f}MB\n"
                f"  Rendiment: {self.system.realtime_stats.get('generations_per_second', 0):.2f} gens/s")
    
    def _format_benchmark(self, benchmark: Dict[str, Any]) -> str:
        """Formata resultats de benchmark."""
        perf = benchmark.get("performance", {})
        return (f"ðŸ† **Resultats Benchmark:**\n"
                f"  Generacions: {benchmark.get('benchmark_config', {}).get('generations', 0)}\n"
                f"  Temps total: {perf.get('total_time', 0):.2f}s\n"
                f"  Temps/gen: {perf.get('avg_time_per_gen', 0):.3f}s\n"
                f"  Gens/s: {perf.get('total_generations_per_second', 0):.2f}\n"
                f"  MemÃ²ria final: {perf.get('final_memory_usage_mb', 0):.1f}MB")
    
    def _generate_creative_interpretation(self, input_text: str, result: Dict[str, Any]) -> str:
        """Genera una interpretaciÃ³ creativa dels resultats."""
        metaphors = [
            "com una dansa de partÃ­cules cÃ²smiques",
            "com un somni fractal que es desenvolupa",
            "com un ecosistema matemÃ tic vivent",
            "com una simfonia geomÃ¨trica",
            "com un llenguatge secret de l'univers"
        ]
        
        import random
        metaphor = random.choice(metaphors)
        
        return (f"âœ¨ La teva idea '{input_text}' s'ha transformat {metaphor}.\n"
                f"ðŸ“Š Complexitat generada: {result['fractal_generation']['branch_count']} branques\n"
                f"ðŸŽ¯ CoherÃ¨ncia: {result['evolution']['final_state']['coherence']:.3f}\n"
                f"ðŸŒ€ Entropia: {result['evolution']['final_state']['entropy']:.3f}")
    
    def _generate_visual_description(self, input_text: str, result: Dict[str, Any]) -> str:
        """Genera una descripciÃ³ visual."""
        visual_elements = [
            "Patrons espirals que s'entrellacen",
            "Geometria cristalÂ·lina en evoluciÃ³",
            "Formes orgÃ niques que creixen i es divideixen",
            "Estructures fractals que s'autosimilaritzen",
            "Textures matemÃ tiques que respiren"
        ]
        
        import random
        element = random.choice(visual_elements)
        
        return (f"ðŸ‘ï¸  VisualitzaciÃ³ generada:\n"
                f"  â€¢ {element}\n"
                f"  â€¢ Profunditat: {result['fractal_generation']['depth']} nivells\n"
                f"  â€¢ TransformaciÃ³ CSS aplicada\n"
                f"  â€¢ Basada en: '{input_text}'")
    
    def _extract_learning_points(self, response_data: Dict[str, Any]) -> str:
        """Extreu punts d'aprenentatge de la resposta."""
        if "application_result" not in response_data:
            return ""
        
        applied = response_data["application_result"].get("parameters_applied", [])
        if not applied:
            return ""
        
        learnings = []
        for param, old_val, new_val in applied:
            change_pct = abs((new_val - old_val) / (old_val + 1e-10)) * 100
            if change_pct > 10:  # Canvis significatius
                direction = "augmentat" if new_val > old_val else "reduÃ¯t"
                learnings.append(f"{param} {direction} de {old_val:.2f} a {new_val:.2f}")
        
        return "; ".join(learnings) if learnings else ""
    
    def _show_history(self, n_str: str) -> str:
        """Mostra l'historial de conversa."""
        try:
            n = int(n_str)
        except ValueError:
            n = 10
        
        history_text = f"ðŸ“œ **Ãšltims {min(n, len(self.conversation_history))} missatges:**\n"
        
        for i, entry in enumerate(self.conversation_history[-n:]):
            role = entry.get("role", "unknown")
            content = entry.get("content", "")[:100] + "..." if len(entry.get("content", "")) > 100 else entry.get("content", "")
            msg_type = entry.get("type", "message")
            
            prefix = "ðŸ‘¤" if role == "user" else "ðŸ¤–"
            if msg_type == "command":
                prefix = "âš™ï¸"
            elif msg_type == "creative":
                prefix = "ðŸŽ¨"
            elif msg_type == "visual":
                prefix = "ðŸ‘ï¸"
            
            history_text += f"{prefix} {content}\n"
        
        return history_text
    
    def _get_timestamp(self) -> str:
        """ObtÃ© un timestamp formatat."""
        from datetime import datetime
        return datetime.now().strftime("%H:%M:%S")
    
    def save_conversation_state(self, filename: str = "conversation_state.json"):
        """Guarda l'estat de la conversa."""
        state = {
            "conversation_history": self.conversation_history,
            "command_history": self.command_history,
            "config_name": self.config_name,
            "modes": {
                "creative": self.creative_mode,
                "visualization": self.visualization_mode,
                "learning": self.learning_mode
            },
            "system_stats": self.system._get_system_state_summary(),
            "timestamp": self._get_timestamp()
        }
        
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(state, f, indent=2, ensure_ascii=False)
    
    def load_conversation_state(self, filename: str = "conversation_state.json") -> bool:
        """Carrega l'estat de la conversa."""
        try:
            if not os.path.exists(filename):
                return False
            
            with open(filename, "r", encoding="utf-8") as f:
                state = json.load(f)
            
            self.conversation_history = state.get("conversation_history", [])
            self.command_history = state.get("command_history", [])
            self.config_name = state.get("config_name", "conversational")
            modes = state.get("modes", {})
            self.creative_mode = modes.get("creative", False)
            self.visualization_mode = modes.get("visualization", False)
            self.learning_mode = modes.get("learning", True)
            
            # Reconstruir sistema si cal
            if self.config_name in ALL_CONFIGS:
                config_obj = get_config_object(self.config_name)
                self.system = SVGelonaAI5_2(config_obj.config.copy())
                self.config = config_obj.config.copy()
            
            return True
            
        except Exception as e:
            print(f"âš  Error carregant estat: {e}")
            return False

def main():
    """FunciÃ³ principal d'execuciÃ³."""
    parser = argparse.ArgumentParser(description='SVGelona_AI 5.2 - InterfÃ­cie Conversacional')
    parser.add_argument('--config', type=str, default='conversational',
                       help='ConfiguraciÃ³ inicial (default: conversational)')
    parser.add_argument('--load', type=str, 
                       help='Carregar estat des d\'un fitxer')
    parser.add_argument('--custom', type=str,
                       help='ConfiguraciÃ³ personalitzada en format JSON')
    
    args = parser.parse_args()
    
    # ConfiguraciÃ³ personalitzada si s'especifica
    custom_config = None
    if args.custom:
        try:
            custom_config = json.loads(args.custom)
            print(f"âœ… ConfiguraciÃ³ personalitzada carregada des d'arguments")
        except json.JSONDecodeError as e:
            print(f"âš  Error parsejant configuraciÃ³ personalitzada: {e}")
            return
    
    # Crear instÃ ncia del sistema
    chatbot = ConversationalSVGelona(
        config_name=args.config,
        custom_config=custom_config
    )
    
    # Carregar estat si s'especifica
    if args.load and chatbot.load_conversation_state(args.load):
        print(f"âœ… Estat carregat des de '{args.load}'")
    
    print("\nðŸ’¬ **Instruccions:**")
    print("  â€¢ Parla normalment amb l'IA")
    print("  â€¢ Utilitza comandes amb / (ex: /help)")
    print("  â€¢ exit/quit per sortir")
    print("-" * 80)
    
    while True:
        try:
            user_input = input("\nðŸ‘¤ Tu: ").strip()
            
            if user_input.lower() in ['exit', 'sortir', 'quit', 'q']:
                print("\nðŸ‘‹ Fins aviat! Recorda que pots guardar l'estat amb /save")
                break
            
            if not user_input:
                continue
            
            # Processar entrada
            response = chatbot.process_command(user_input)
            
            # Mostrar resposta
            if response["type"] == "command_response":
                print(f"\nâš™ï¸  Sistema: {response['message']}")
                if response.get("data"):
                    for key, value in response["data"].items():
                        if isinstance(value, dict):
                            for subkey, subvalue in value.items():
                                print(f"    {subkey}: {subvalue}")
            elif "narrative_response" in response:
                print(f"\nðŸ¤– SVGelona_AI: {response['narrative_response']}")
                
                # Mostrar canvis aplicats
                if (response.get("application_result", {}).get("success") and 
                    "parameters_applied" in response.get("application_result", {})):
                    print("\nâš™ï¸  Canvis aplicats:")
                    for param, old_val, new_val in response["application_result"]["parameters_applied"]:
                        change = new_val - old_val
                        arrow = "â†‘" if change > 0 else "â†“" if change < 0 else "â†’"
                        print(f"  â€¢ {param}: {old_val:.3f} {arrow} {new_val:.3f}")
            
            elif "error" in response.get("type", ""):
                print(f"\nâŒ Error: {response.get('narrative_response', 'Error desconegut')}")
        
        except KeyboardInterrupt:
            print("\n\nâš  Interromput per l'usuari.")
            save_choice = input("Vols guardar l'estat abans de sortir? (s/n): ").lower()
            if save_choice == 's':
                chatbot.save_conversation_state()
                print("ðŸ’¾ Estat guardat!")
            break
        
        except Exception as e:
            print(f"\nâš  Error inesperat: {e}")
            continue
    
    # Guardar historial de conversa automÃ ticament
    if chatbot.conversation_history:
        auto_save = "conversation_auto_save.json"
        chatbot.save_conversation_state(auto_save)
        print(f"\nðŸ’¾ Historial de conversa guardat automÃ ticament a '{auto_save}'")
    
    print("=" * 80)

if __name__ == "__main__":
    main()